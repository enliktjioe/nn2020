{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1\n",
    "\n",
    "\n",
    "The homework consists of two parts: theoretical part (10 pts) and coding part (20 pts).\n",
    " - All theoretical questions must be answered in your own words, do not copy-paste text from the internet. Points can be deducted for terrible formatting or incomprehensible English.\n",
    " - Code must be commented. If you use code you found online, you have to add the link to the source you used. There is no penalty for using outside sources as long as you convince us you understand the code.\n",
    "\n",
    "*Once completed zip the entire directory containing this exercise and upload it to https://courses.cs.ut.ee/2020/nn/spring/Main/Practices.*\n",
    "\n",
    "For background reading see http://cs231n.github.io/classification/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you did this homework together with course mates, please write here their names (answers still have to be your own!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name(s):** *fill this in if applicable*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Lecture Materials (10 pts)\n",
    "\n",
    "These questions are about the material covered in the two lectures about \"Probability and Information theory\" and \"Basics of Machine Learning\".\n",
    "\n",
    "### Probability theory\n",
    "\n",
    "**Task 1.1 (3pts)**\n",
    "Some guys made a study to find out if intake of vitamin C helps you recover faster from a common cold. They asked 1000 people about their recent illness and if they consumed additional vitamin C. The results are summarized in table below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|                       -            | Recovered in <3 days | Recovered in 3-5 days | Recovered in >5 days | Total probability of dose |\n",
    "|------------------------------------|----------------------|-----------------------|----------------------|---------------------------|\n",
    "| **No vitamin C**                       | 200 participants     | 150 participants      | 150 participants     |                           |\n",
    "| **Low dose of vitamin C**              | 80 participants      | 60 participants       | 60 participants      |                           |\n",
    "| **High dose of vitamin C**             | 120 participants     | 90 participants       | 90 participants      |                           |\n",
    "| **Total probability of recovery time** |         -            |        -              |         -            |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer the following questions, also include explanation or calculations that led to this answer. (It is probably best if you turn the counts into probabilities first and calculate marginal probabilities)\n",
    " 1. What proportion of the participants took more than 5 days to recover from illness?\n",
    " 2. What is the probability to recover in less than 3 days given that you took no vitamin C? (HINT: it is a conditional probability)\n",
    " 3. What is the probability to recover in less than 3 days given that you took high dose of vitamin C?\n",
    " 4. Are the two variables (dose and recovery time) independent? Explain your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer**: *fill this in.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1.2 (3pts)** Imagine we have a classifier that classifies an image into one of 4 categories: cars, bicycles, motorbikes and pedestrians. Given an image of a bicycle, it produces the following probabilities for the 4 classes: car 0.05, bicycle 0.70, motorbike 0.20, pedestrian 0.05. Considering that the true probability distribution is $[0,1,0,0]$, find (use base 2 for all the logarithms):\n",
    " - The entropy of the true distribution, the predicted distribution and a uniform distribution ($[0.25,0.25,0.25,0.25]$). Which one is the highest?\n",
    " - Kullback-Leibler divergence between the true and the predicted distribution.<br/> (notice that $KL(p||q)$ is not equal to $KL(q||p)$ )\n",
    " - Sum up the entropy of the true distribution and the KL divergence calculated above to get the cross-entropy value. Calculate the cross-entropy also using the formula $CE(p,q) = - \\sum_i p_i log_2(q_i).$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer**: *fill this in.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning\n",
    "\n",
    "**Task 1.3 (1pt)**\n",
    "Suppose you have measured a series of pairs of values $y_i$ and $x_i$, for $i=1,\\dots,N$, and you would like to establish some relation between the X and Y variables. Assume also that each sample is independent and identically distributed. Show that the maximum likelihood estimator for the Gaussian model of linear regression corresponds to minimizing the mean squared error between the prediction and the true output. Gaussian model assumes that the probability of some target value y given x is the Gaussian distribution $\\mathcal{N}(w\\cdot x, \\sigma^2)$, where w are the weights.\n",
    "\n",
    "In particular demonstrate that maximizing\n",
    "$\n",
    "%\\arg \\max_\\theta \n",
    "\\log \\left(\\frac{1}{\\sqrt{2\\pi\\sigma^2}}e^{-\\frac{(y - \\hat{y})^2}{2\\sigma^2}}\\right)\n",
    "$\n",
    "is equivalent to minimizing \n",
    "$\n",
    "%= \\arg \\min_\\theta \n",
    "(y - \\hat{y})^2\n",
    "$, where $y$ is the target value, $\\hat{y}=w\\cdot x$ is the predicted value and variance $\\sigma^2$ is considered constant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer**: *fill this in.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1.4 (1pt)** Imagine you have trained a very powerful neural network to classify if a given image has a dog or a cat on it. The network achieves 99.9% accuracy on the images that it was trained on, but has only 65% accuracy on cat/dog images it has never seen before (test images). How is this problem called? How to make the difference between training and testing error smaller (name at least one solution)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer**: *fill this in.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1.5: Curse of Dimensionality (2pts)**\n",
    "Images are very common data type in deep learning. Each colored image consists of pixels, each pixel is a combination of three color values - red,green,blue - that have 256 possible values each.\n",
    " - How many different colors can one pixel take?\n",
    " - How many different $2\\times2$ pixel images are there?\n",
    " - In the ImageNet dataset the pictures are of size $256\\times256$ pixels. Compare the number of possible images with the number of images in the dataset (1.2 million)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer**: *fill this in.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: k-Nearest Neighbor (kNN) exercise (20 pts)\n",
    "\n",
    "In this assignment you will\n",
    " - understand the basic Image Classification pipeline and the data-driven approach (train/predict stages),\n",
    " - understand the train/val/test splits and the use of validation data for hyperparameter tuning,\n",
    " - develop proficiency in writing efficient vectorized code with numpy,\n",
    " - implement and apply a k-Nearest Neighbor (kNN) classifier.\n",
    "\n",
    "### Requirements\n",
    "\n",
    "All the required packages should be part of Anaconda already, the only additional install is `future` package (only needed if using Python 2) :\n",
    "```\n",
    "conda install future\n",
    "```\n",
    "\n",
    "### Downloading data\n",
    "\n",
    "Download the CIFAR-10 dataset from http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz and untar it to <br/> `../datasets`:\n",
    "```\n",
    "tar -xzvf cifar-10-python.tar.gz\n",
    "```\n",
    "\n",
    "### kNN\n",
    "\n",
    "The kNN classifier consists of two stages:\n",
    "\n",
    "- Stage I: During training, the classifier takes the training data and simply remembers it\n",
    "- Stage II: During testing, kNN classifies every test image by comparing it to all training images. The most common label among the k most similar training examples is given as the output.\n",
    "\n",
    "The optimal value of k is found via cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run some setup code for this notebook.\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "from data_utils import load_CIFAR10\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# This is a bit of magic to make matplotlib figures appear inline in the notebook\n",
    "# rather than in a new window.\n",
    "%matplotlib inline\n",
    "\n",
    "# Other plotting-related parameters\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules.\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the raw CIFAR-10 data.\n",
    "cifar10_dir = '../datasets/cifar-10-batches-py'\n",
    "X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "\n",
    "# As a sanity check, we print out the size of the training and test data.\n",
    "print('Training data shape: ', X_train.shape)\n",
    "print('Training labels shape: ', y_train.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualize some examples from the dataset.\n",
    "# We show a few examples of training images from each class.\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "num_classes = len(classes)\n",
    "samples_per_class = 7\n",
    "for y, cls in enumerate(classes):\n",
    "    idxs = np.flatnonzero(y_train == y)\n",
    "    idxs = np.random.choice(idxs, samples_per_class, replace=False)\n",
    "    for i, idx in enumerate(idxs):\n",
    "        plt_idx = i * num_classes + y + 1\n",
    "        plt.subplot(samples_per_class, num_classes, plt_idx)\n",
    "        plt.imshow(X_train[idx].astype('uint8'))\n",
    "        plt.axis('off')\n",
    "        if i == 0:\n",
    "            plt.title(cls)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Subsample the data for more efficient code execution in this exercise\n",
    "# We use just 1/10 th of the data\n",
    "num_training = 5000\n",
    "mask = list(range(num_training))\n",
    "X_train = X_train[mask]\n",
    "y_train = y_train[mask]\n",
    "\n",
    "num_test = 500\n",
    "mask = list(range(num_test))\n",
    "X_test = X_test[mask]\n",
    "y_test = y_test[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reshape the image data into rows\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from k_nearest_neighbor import KNearestNeighbor\n",
    "\n",
    "# Create a kNN classifier instance. \n",
    "# Remember that training a kNN classifier is a noop: \n",
    "# the Classifier simply remembers the data and does no further processing \n",
    "classifier = KNearestNeighbor()\n",
    "classifier.train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would now like to classify the test data with the kNN classifier. Recall that we can break down this process into two steps: \n",
    "\n",
    "1. Phase I of testing: First we must compute the distances between all test examples and all train examples. \n",
    "2. Phase II of testing: Given these distances, for each test example we find the k nearest examples and have them vote for the label\n",
    "\n",
    "Lets begin with computing the distance matrix between all training and test examples. For example, if there are **N_tr** training examples and **N_te** test examples, this stage should result in a **N_te x N_tr** matrix where each element $(i,j)$ is the distance between the $i$-th test and $j$-th train example.\n",
    "\n",
    "**Task 2.1 (3pts):** First, open `k_nearest_neighbor.py` and implement the function `compute_distances_two_loops` that uses a (very inefficient) double loop over all pairs of (test, train) examples and computes the distance matrix one element at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Open k_nearest_neighbor.py and implement\n",
    "# compute_distances_two_loops.\n",
    "\n",
    "# Test your implementation:\n",
    "dists = classifier.compute_distances_two_loops(X_test)\n",
    "print(\"The shape of the distances matrix:\", dists.shape)\n",
    "\n",
    "assert not np.all(dists==0), \"ERROR: The function seems to not be implemented, the output is all zeros\"\n",
    "assert np.isclose(dists[0,1],4210.59603857), \"ERROR: The function seems to not be correct - an answer does not match with what we got\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can visualize the distance matrix: each row reflects a single test example and\n",
    "# its distances to training examples\n",
    "plt.imshow(dists, interpolation='none')\n",
    "plt.xlabel(\"train images\")\n",
    "plt.ylabel(\"test images\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2.2 (1pt):** Notice the structured patterns in the distance matrix, where some rows or columns are visible brighter. (Note that with the default color scheme black indicates low distances while white indicates high distances.)\n",
    "\n",
    "- What in the data is the cause behind the distinctly bright rows?\n",
    "- What causes the columns?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer**: *fill this in.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2.3 (3pts):** Now implement the function `predict_labels` in `k_nearest_neighbor.py` and run the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We use k = 1 (which is Nearest Neighbor).\n",
    "y_test_pred = classifier.predict_labels(dists, k=1)\n",
    "\n",
    "# Compute and print the fraction of correctly predicted examples\n",
    "num_correct = np.sum(y_test_pred == y_test)\n",
    "accuracy = float(num_correct) / num_test\n",
    "print('Got %d / %d correct => accuracy: %f' % (num_correct, num_test, accuracy))\n",
    "assert np.isclose(accuracy,0.274), \"The accuracy is not correct, there is some problem\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should expect to see approximately `27%` accuracy. Now lets try out a larger `k`, say `k = 5`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_pred = classifier.predict_labels(dists, k=5)\n",
    "num_correct = np.sum(y_test_pred == y_test)\n",
    "accuracy = float(num_correct) / num_test\n",
    "print('Got %d / %d correct => accuracy: %f' % (num_correct, num_test, accuracy))\n",
    "assert np.isclose(accuracy,0.278), \"The accuracy is not correct, there is some problem\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should expect to see a slightly better performance than with `k = 1`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2.4 (3pts):** Now lets speed up distance matrix computation by using partial vectorization with one loop. Implement the function `compute_distances_one_loop` in `k_nearest_neighbor.py` and run the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dists_one = classifier.compute_distances_one_loop(X_test)\n",
    "\n",
    "# To ensure that our vectorized implementation is correct, we make sure that it\n",
    "# agrees with the naive implementation. There are many ways to decide whether\n",
    "# two matrices are similar; one of the simplest is the Frobenius norm. In case\n",
    "# you haven't seen it before, the Frobenius norm of two matrices is the square\n",
    "# root of the squared sum of differences of all elements; in other words, reshape\n",
    "# the matrices into vectors and compute the Euclidean distance between them.\n",
    "difference = np.linalg.norm(dists - dists_one, ord='fro')\n",
    "print('Difference was: %f' % (difference, ))\n",
    "if difference < 0.001:\n",
    "    print('Good! The distance matrices are the same')\n",
    "else:\n",
    "    print('Uh-oh! The distance matrices are different')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2.5 (6pts):** Now implement the fully vectorized version inside `compute_distances_no_loops` in `k_nearest_neighbor.py` and run the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dists_two = classifier.compute_distances_no_loops(X_test)\n",
    "\n",
    "# check that the distance matrix agrees with the one we computed before:\n",
    "difference = np.linalg.norm(dists - dists_two, ord='fro')\n",
    "print('Difference was: %f' % (difference, ))\n",
    "if difference < 0.001:\n",
    "    print('Good! The distance matrices are the same')\n",
    "else:\n",
    "    print('Uh-oh! The distance matrices are different')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's compare how fast the implementations are\n",
    "def time_function(f, *args):\n",
    "    \"\"\"\n",
    "    Call a function f with args and return the time (in seconds) that it took to execute.\n",
    "    \"\"\"\n",
    "    import time\n",
    "    tic = time.time()\n",
    "    f(*args)\n",
    "    toc = time.time()\n",
    "    return toc - tic\n",
    "\n",
    "two_loop_time = time_function(classifier.compute_distances_two_loops, X_test)\n",
    "print('Two loop version took %f seconds' % two_loop_time)\n",
    "\n",
    "one_loop_time = time_function(classifier.compute_distances_one_loop, X_test)\n",
    "print('One loop version took %f seconds' % one_loop_time)\n",
    "\n",
    "no_loop_time = time_function(classifier.compute_distances_no_loops, X_test)\n",
    "print('No loop version took %f seconds' % no_loop_time)\n",
    "\n",
    "# you should see significantly faster performance with the fully vectorized implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation\n",
    "\n",
    "We have implemented the k-Nearest Neighbor classifier but we set the value `k = 5` arbitrarily. We will now determine the best value of this hyperparameter with cross-validation.\n",
    "\n",
    "**Task 2.6 (1pt):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_folds = 5\n",
    "k_choices = [1, 3, 5, 8, 10, 12, 15, 20, 50, 100]\n",
    "\n",
    "X_train_folds = []\n",
    "y_train_folds = []\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Split up the training data into folds. After splitting, X_train_folds and    #\n",
    "# y_train_folds should each be lists of length num_folds, where                #\n",
    "# y_train_folds[i] is the label vector for the points in X_train_folds[i].     #\n",
    "# Hint: Look up the numpy.array_split function.                                #\n",
    "################################################################################\n",
    "pass\n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             #\n",
    "################################################################################\n",
    "assert np.shape(X_train_folds)==(5, 1000, 3072), \"the shape of folds is not correct\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2.7 (3pts):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A dictionary holding the accuracies for different values of k that we find\n",
    "# when running cross-validation. After running cross-validation,\n",
    "# k_to_accuracies[k] should be a list of length num_folds giving the different\n",
    "# accuracy values that we found when using that value of k.\n",
    "k_to_accuracies = {}\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Perform k-fold cross validation to find the best value of k. For each        #\n",
    "# possible value of k, run the k-nearest-neighbor algorithm num_folds times,   #\n",
    "# where in each case you use all but one of the folds as training data and the #\n",
    "# last fold as a validation set. Store the accuracies for all fold and all     #\n",
    "# values of k in the k_to_accuracies dictionary.                               #\n",
    "################################################################################\n",
    "pass\n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             #\n",
    "################################################################################\n",
    "\n",
    "# Print out the computed accuracies\n",
    "for k in sorted(k_to_accuracies):\n",
    "    for accuracy in k_to_accuracies[k]:\n",
    "        print('k = %d, accuracy = %f' % (k, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot the raw observations\n",
    "for k in k_choices:\n",
    "    accuracies = k_to_accuracies[k]\n",
    "    plt.scatter([k] * len(accuracies), accuracies)\n",
    "\n",
    "# plot the trend line with error bars that correspond to standard deviation\n",
    "accuracies_mean = np.array([np.mean(v) for k,v in sorted(k_to_accuracies.items())])\n",
    "accuracies_std = np.array([np.std(v) for k,v in sorted(k_to_accuracies.items())])\n",
    "plt.errorbar(k_choices, accuracies_mean, yerr=accuracies_std)\n",
    "plt.title('Cross-validation on k')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Cross-validation accuracy')\n",
    "plt.show()\n",
    "\n",
    "print('Best k:', k_choices[np.argmax(accuracies_mean)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Based on the cross-validation results above, choose the best value for k,   \n",
    "# retrain the classifier using all the training data, and test it on the test\n",
    "# data. You should be able to get above 28% accuracy on the test data.\n",
    "\n",
    "#TODO: fill this in with best value\n",
    "best_k = 1\n",
    "\n",
    "classifier = KNearestNeighbor()\n",
    "classifier.train(X_train, y_train)\n",
    "y_test_pred = classifier.predict(X_test, k=best_k)\n",
    "\n",
    "# Compute and display the accuracy\n",
    "num_correct = np.sum(y_test_pred == y_test)\n",
    "accuracy = float(num_correct) / num_test\n",
    "print('Got %d / %d correct => accuracy: %f' % (num_correct, num_test, accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
